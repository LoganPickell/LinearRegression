# -*- coding: utf-8 -*-
"""Logan Pickell Project1 One Variable.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yTlqzg5gYO1sPPgXCGeledsJvcyE-M8H

Logan Pickell   
Artificial Intelligence   
CPSC4383   
Project 1   
Linear Regression model

A linear regression model takes a set of known input points and finds the best straight line fit.

![linear-regression.png](data:image/png;base64,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)

# Import files and libraries
"""

from google.colab import files
uploaded = files.upload()
filename = 'ex1data1.csv'



# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
# %matplotlib inline
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv(filename)
df.head(2)

"""# Visualize Data"""

#I used a Seaborn lmplot to visualize the regression line of this data
sns.lmplot(x="Population", y="Profit", data=df)

"""
# Configure Plot Options"""

plt.rcParams['figure.dpi']=104
plt.rcParams['figure.figsize'] = [6,4]
plt.rcParams['figure.facecolor']= '#888888'
plt.rcParams['font.size']=14
plt.rcParams['lines.linewidth']= 3
plt.rcParams['lines.color'] = 'red'

"""# Define Functions to Plot Points and Lines"""

def vPlotPoint(x,y) : plt.scatter(x,y,marker='x', color='#0000ff', zorder=10);

def vPlotPoints(x,y):
  ax = plt.axes();
  ax.set_facecolor('#99cc99')
  plt.xlabel('Population')
  plt.ylabel('Profit')
  plt.title('Profit vs Population')
  plt.scatter(x,y,marker='o',color='#000077',zorder=5);

def vLine(x,m,b):
    plt.plot(x,m*x +b, color ='#bb0000', linewidth =3, zorder=0);

"""# Split Data Into Training and Test Sets

I believe this will randomly split the values into test and train data sets. This will cause the data to be a little more inconsistent through different trials.
"""

x_train, x_test, y_train, y_test = train_test_split(df.Population, df.Profit, test_size = 0.2)
print("x_train: ", np.array(x_train).reshape(-1,1))
print("y_train: ", np.array(y_train).reshape(-1,1))

print("x_test: ", np.array(x_test).reshape(-1,1))
print( )
print("y_test: ", np.array(y_test).reshape(-1,1))

"""# Create Arrays of the Correct Size and Fit a Linear Regression line

"""

x = np.array([x_train]).reshape((-1,1))
y = np.array([y_train]).reshape((-1,1))
model = LinearRegression()
model.fit(x, y)

"""# Expressing Coefficient of Determination"""

R_squared = model.score(x,y)
print ('Coefficient of Determination: ', round(R_squared, 2))
print ('We have a ', int(100*round(R_squared,2)), '% certainty that Population explains Profit.', sep='')

"""# Finding Intercept and Slope of Linear Regression Line"""

b = model.intercept_
m = model.coef_[0]
print('intercept: ', b)
print('slope: ', m)

vPlotPoints(x,y)
vLine(x,m,b)

"""# Comparing Test Data Predictions to y_test"""

predictions = model.predict(np.array(x_test).reshape(-1,1))
print(predictions)

print(np.array(y_test).reshape(-1,1))

vPlotPoints(x_test,predictions)
plt.plot(x_test,y_test,'bo',color ='#000000');
plt.legend(['Predicted', 'Actual'], loc=2)
vLine(x,m,b)

"""# Sum of Squared Error"""

residuals = predictions - np.array(y_test).reshape(-1,1)
print(np.array(residuals))

squared = residuals * residuals
sse = sum(squared/len(residuals))
print(sse)

"""# Distribution of Error"""

plt.hist(residuals)
plt.ylabel('# of Ocurrances')
plt.xlabel('Error Value')